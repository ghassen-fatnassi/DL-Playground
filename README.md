# DL-Playground

Welcome to the **DL-Playground**, a collection of experimental deep learning ideas!

## Projects

1. **Batch Size vs. Inference Time**
   - **Objective**: Demonstrate the effect of batch size on inference time and identify when increasing batch size no longer provides performance benefits.
   - **Models Explored**: RNN, CNN, MLP, Transformer.
   - **Kaggle Notebook**: [Batch Size x Inference Time](https://www.kaggle.com/code/musclnbrains/batch-size-x-inference-time)

2. **Dropout as a Metric of Model Overfitting**
   - **Objective**: Experiment to show that if a modelâ€™s performance can withstand dropout during evaluation, it is proportionally more amenable to pruning or distillation.
   - **Kaggle Notebook**: [Dropout & Overfitting](https://www.kaggle.com/code/musclnbrains/dropout-as-a-way-to-measure-model-overfitting)

3. **Gradient vs. Laplacian on Images**
   - **Objective**: Illustrate that the Laplacian operator is superior to the gradient operator for edge detection, using the Olivetti Faces dataset.
   - **Kaggle Notebook**: [Gradient vs. Laplacian](https://www.kaggle.com/code/musclnbrains/gradient-vs-laplacien-on-image)
4. **PCA for Face Classification**  
   - **Objective**: Demonstrate Principal Component Analysis (PCA) for dimensionality reduction and binary classification of face vs. no-face images using a Kaggle face dataset and CIFAR-10.  
   - **Kaggle Notebook**: [PCA EigenFaces](https://www.kaggle.com/code/musclnbrains/pca-eigenfaces)
5. **GODS4.0 5th place submission**
   - **Objective**: This 12 hour Zindi competition focuses on classifying mental health data ,our team used  a bunch of techniques , my contribution was the Longformer-based model with techniques like resampling and mixed precision training, we managed to make it run distributed on kaggle 2T4 gpu's tp get it to work before submission time
   - **Kaggle Notebook**: [GODS4.0](https://www.kaggle.com/code/musclnbrains/gods4-0)

Feel free to explore, experiment, and share feedback on these mini ideas!
